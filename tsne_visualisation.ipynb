{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import DENOISERS_ARCHITECTURES, get_architecture, IMAGENET_CLASSIFIERS, CLASSIFIERS_ARCHITECTURES\n",
    "from datasets import get_dataset, DATASETS, get_num_classes, get_normalize_layer\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# Directory\n",
    "parser.add_argument('--data-dir', default='data/', help='data path')\n",
    "parser.add_argument('--ckpt-dir', default='checkpoint_unet/', help='checkpoint path')\n",
    "parser.add_argument('--pretrained', default='../denoised-smoothing/pretrained_models/cifar10_classifiers/ResNet110_90epochs/noise_0.00/checkpoint.pth.tar', help='pretrained_model path')\n",
    "parser.add_argument('--pretrained-denoiser', default='../denoised-smoothing/pretrained_models/trained_denoisers/cifar10/stab_obj/cifar10_smoothness_obj_adamThenSgd_6/multi_classifiers/dncnn/noise_0.12/checkpoint.pth.tar', help='pretrained_model path')\n",
    "parser.add_argument('--noise-sd', type=float, default=0.12, help='sd for noise')\n",
    "parser.add_argument('--name', type=str, default='mnet_unet0.00_csv1', help='name of saved checkpoints')\n",
    "parser.add_argument('--dataset', default='cifar10', choices=DATASETS)\n",
    "parser.add_argument('--split', default='test', choices=['train','test'])\n",
    "parser.add_argument('--type', default='ds', choices=['ours','ds', 'rs'])\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(args.dataset, args.split)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=8)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=8)\n",
    "\n",
    "classes =  {0:'airplane',\n",
    "            1:'automobile',\n",
    "            2:'bird',\n",
    "            3:'cat',\n",
    "            4:'deer',\n",
    "            5:'dog',\n",
    "            6:'frog',\n",
    "            7:'horse',\n",
    "            8:'ship',\n",
    "            9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(pipeline, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        if args.type=='ours':\n",
    "            x = normalize(input)\n",
    "        else:\n",
    "            x = input\n",
    "        n = torch.randn(x.shape).cuda()*args.noise_sd\n",
    "        return self.model[0](x + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "if args.type in ['ours','ds']:\n",
    "    if args.type =='ours':\n",
    "        print('=====> Loading trained model from checkpoint...')\n",
    "        noise_sd = 0.25\n",
    "        checkpoint = torch.load(args.ckpt_dir + args.name + '.ckpt')\n",
    "\n",
    "        model = checkpoint['model']\n",
    "        rng_state = checkpoint['rng_state']\n",
    "        torch.set_rng_state(rng_state)\n",
    "    elif args.type =='ds':\n",
    "        if args.pretrained_denoiser:\n",
    "            print('=====> Loading Pretrained Classifier...')\n",
    "            checkpoint = torch.load(args.pretrained_denoiser)\n",
    "            model = get_architecture(checkpoint['arch'], args.dataset)\n",
    "            model.load_state_dict(checkpoint['state_dict'], strict=False)       \n",
    "\n",
    "    if args.pretrained:\n",
    "        print('=====> Loading Pretrained Classifier...')\n",
    "        checkpoint = torch.load(args.pretrained)\n",
    "        cs_model = get_architecture(checkpoint['arch'], args.dataset)\n",
    "        cs_model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    \n",
    "    \n",
    "    model = torch.nn.Sequential(model, cs_model).to(device)\n",
    "    \n",
    "elif args.type == 'rs':\n",
    "    if args.pretrained:\n",
    "        print('=====> Loading Pretrained Classifier...')\n",
    "        checkpoint = torch.load(args.pretrained)\n",
    "        model = get_architecture(checkpoint['arch'], args.dataset)\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False) \n",
    "        \n",
    "model.eval()\n",
    "\n",
    "pipe = pipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_prob = torch.cat([pipe(X.to(device)).detach().cpu() for X,_ in data_loader], dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(iter(test_loader))\n",
    "y_label = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([classes[i] for i in y_label], columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['label']\n",
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = StandardScaler().fit_transform(recon_prob)\n",
    "tsne_res = tsne.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "sns.scatterplot(x = tsne_res[:,0], y = tsne_res[:,1], hue = label, palette = sns.hls_palette(10), legend = 'full');\n",
    "plt.axis('off')\n",
    "plt.savefig(path + 'image{}.png'.format(args.noise_sd), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me_jpy",
   "language": "python",
   "name": "me_jpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "1dbba7456d667d5b5a14aed01b18b1d848865ee52fadd78bd50701c54b1e38b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}